{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **All Data Cleaning Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_columns(base_cols, years):\n",
    "    return [f\"{col}{year}\" for col in base_cols for year in years]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = range(2023, 2027)\n",
    "years = range(2020, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read formatted linked persons\n",
    "final23 = pd.read_csv(\"processed/final23.csv\")    # Linked class of 2023\n",
    "final24 = pd.read_csv(\"processed/final24.csv\")    # Linked class of 2024\n",
    "final25 = pd.read_csv(\"processed/final25.csv\")    # Linked class of 2025\n",
    "final26 = pd.read_csv(\"processed/final26.csv\")    # Linked class of 2026\n",
    "all_linked = pd.concat([final23, final24, final25, final26], ignore_index=True, axis=0)\n",
    "\n",
    "final = {\n",
    "    2023: final23,\n",
    "    2024: final24,\n",
    "    2025: final25,\n",
    "    2026: final26,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Numerical Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    num_cols = df.select_dtypes(include=['int', 'float']).columns\n",
    "    df[num_cols] = df[num_cols].fillna(-1)\n",
    "    \n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    df[cat_cols] = df[cat_cols].fillna(\"missing\")\n",
    "    \n",
    "    df = df.replace({True: 1, False: 0, \"missing\": -1})\n",
    "    \n",
    "    genderid_cols = get_yearly_columns([\"SBJ.FCT.GenderId\", \"SBJ.FCT.Sex\", \"SBJ.FCT.Sexuality\"], years)\n",
    "    df[genderid_cols] = df[genderid_cols].replace({\n",
    "        \"Boy/ man/ male\": 1, \n",
    "        \"Boy/man/male\": 1,\n",
    "        \"Girl/ woman/ female\": 2,\n",
    "        \"Girl/woman/female\": 2,\n",
    "        \"Transgender male\": 3,\n",
    "        \"Transgender boy/man/male\": 3,\n",
    "        \"Transgender female\": 4,\n",
    "        \"Transgender Girl/woman/female\": 4,\n",
    "        \"Non-binary, genderqueer, or not exclusively male or female\": 5,\n",
    "        \"Another gender\": 6,\n",
    "        \"Not sure\": 7,\n",
    "        \"I don't want to say\": 8,\n",
    "        \"Male\": 0,\n",
    "        \"Female\": 1,\n",
    "        \"Asexual\": 6,\n",
    "        \"Bisexual\": 3,\n",
    "        \"Gay or Lesbian\": 2,\n",
    "        \"I don't want to say\": 10,\n",
    "        \"Pansexual\": 5,\n",
    "        \"Queer\": 4,\n",
    "        \"Something else\": 7,\n",
    "        \"Straight or heterosexual\": 1,\n",
    "        \"Straight\": 1,\n",
    "        \"Unsure\": 8,\n",
    "        \"I haven't thought about it or I don't know what this question means\": 9,\n",
    "        \"Questioning or still figuring it out\": 8,\n",
    "    })\n",
    "    \n",
    "    ethnicity_cols = get_yearly_columns([\"SBJ.FCT.Ethnicity\"], years)\n",
    "    df[ethnicity_cols] = df[ethnicity_cols].replace({\n",
    "        \"Hispanic/ Latino(a)\": 1, \n",
    "        \"Not Hispanic/ Latino(a)\": 0,\n",
    "        \"Hispanic/ latino(a)\": 1,\n",
    "        \"Not Hispanic/latino(a)\": 0,\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, cat_cols):\n",
    "    df[cat_cols] = df[cat_cols].applymap(float)\n",
    "    encoder = OneHotEncoder(sparse_output=False, dtype=int, handle_unknown=\"ignore\")\n",
    "    encoded_array = encoder.fit_transform(df[cat_cols])\n",
    "    encoded_columns = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "    # Match \"BaseVariableYYYY_Category\"\n",
    "    def reformat_column_name(col_name):\n",
    "        match = re.search(r\"(.*?)(\\d{4})_(.*)\", col_name)  \n",
    "        if match:\n",
    "            base_var, year, category = match.groups()\n",
    "            return f\"{base_var}_{category}{year}\"\n",
    "        return col_name\n",
    "\n",
    "    reformatted_columns = [reformat_column_name(col) for col in encoded_columns]\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=reformatted_columns)\n",
    "\n",
    "    df_encoded = df.drop(columns=cat_cols).reset_index(drop=True)\n",
    "    df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols = {\n",
    "    \"INV.DBL.APSS.Q1.MindReading\",\n",
    "    \"INV.DBL.APSS.Q2.TVRadio\",\n",
    "    \"INV.DBL.APSS.Q3.Spying\",\n",
    "    \"INV.DBL.APSS.Q4.Auditory\",\n",
    "    \"INV.DBL.APSS.Q5.Controlled\",\n",
    "    \"INV.DBL.APSS.Q6.Visual\",\n",
    "    \"INV.DBL.APSS.Q7.Grandiosity\",\n",
    "    \"INV.INT.ERS.Q01.Persistence1\",\n",
    "    \"INV.INT.ERS.Q02.Sensitivity1\",\n",
    "    \"INV.INT.ERS.Q03.IntensityArousal1\",\n",
    "    \"INV.INT.ERS.Q04.IntensityArousal2\",\n",
    "    \"INV.INT.ERS.Q05.Sensitivity2\",\n",
    "    \"INV.INT.ERS.Q06.IntensityArousal3\",\n",
    "    \"INV.INT.ERS.Q07.Sensitivity3\",\n",
    "    \"INV.INT.ERS.Q08.Persistence2\",\n",
    "    \"INV.INT.ERS.Q09.Sensitivity4\",\n",
    "    \"INV.INT.ERS.Q10.Persistence3\",\n",
    "    \"INV.INT.ERS.Q11.Persistence4\",\n",
    "    \"INV.INT.ERS.Q12.Sensitivity5\",\n",
    "    \"INV.INT.ERS.Q13.Sensitivity6\",\n",
    "    \"INV.INT.ERS.Q14.Sensitivity7\",\n",
    "    \"INV.INT.ERS.Q15.Sensitivity8\",\n",
    "    \"INV.INT.ERS.Q16.Sensitivity9\",\n",
    "    \"INV.INT.ERS.Q17.IntensityArousal4\",\n",
    "    \"INV.INT.ERS.Q18.Sensitivity10\",\n",
    "    \"INV.INT.ERS.Q19.IntensityArousal5\",\n",
    "    \"INV.INT.ERS.Q20.IntensityArousal6\",\n",
    "    \"INV.INT.ERS.Q21.IntensityArousal7\",\n",
    "    \"INV.INT.PHQ4.Q1.Anxious\",\n",
    "    \"INV.INT.PHQ4.Q2.Worried\",\n",
    "    \"INV.INT.PHQ4.Q3.Depressed\",\n",
    "    \"INV.INT.PHQ4.Q4.Anhedonia\",\n",
    "    \"INV.INT.SUB.Alcohol.Past30\",\n",
    "    \"INV.INT.SUB.Cannabis.Past30\",\n",
    "    \"INV.INT.SUB.Cigarettes.Past30\",\n",
    "    \"INV.INT.SUB.Cigars.Past30\",\n",
    "    \"INV.INT.SUB.Smokeless.Past30\",\n",
    "    \"INV.INT.SUB.Vapes.Past30\",\n",
    "}\n",
    "\n",
    "quant_cols = {\n",
    "    \"INV.DBL.APSS.Total\",\n",
    "    \"INV.INT.ERS.IntensityArousalTotal\",\n",
    "    \"INV.INT.ERS.PersistenceTotal\",\n",
    "    \"INV.INT.ERS.SensitivityTotal\",\n",
    "    \"INV.INT.ERS.Total\",\n",
    "    \"INV.INT.PHQ4.Anxiety\",\n",
    "    \"INV.INT.PHQ4.Depression\",\n",
    "    \"INV.INT.PHQ4.Total\",\n",
    "}\n",
    "\n",
    "cat_cols = {\n",
    "    \"INV.LGL.PHQ4.Anxiety\",\n",
    "    \"INV.LGL.PHQ4.Depression\",\n",
    "    \"INV.INT.SI.Attempt\",\n",
    "    \"INV.INT.SI.How\",\n",
    "    \"INV.INT.SI.Selfharm\",\n",
    "    \"INV.INT.SI.Thoughts\",\n",
    "    \"INV.LGL.SUB.Alcohol.Life\",\n",
    "    \"INV.LGL.SUB.Cannabis.Life\",\n",
    "    \"INV.LGL.SUB.Cigarettes.Life\",\n",
    "    \"INV.LGL.SUB.Cigars.Life\",\n",
    "    \"INV.LGL.SUB.Smokeless.Life\",\n",
    "    \"INV.LGL.SUB.Vapes.Life\",\n",
    "    \"INV.LGL.HelpSeeking0\",\n",
    "    \"INV.LGL.HelpSeeking1\",\n",
    "    \"INV.LGL.HelpSeeking2\",\n",
    "    \"INV.LGL.HelpSeeking3\",\n",
    "    \"INV.LGL.HelpSeeking4\",\n",
    "    \"INV.LGL.HelpSeeking5\",\n",
    "    \"INV.LGL.HelpSeeking6\",\n",
    "    \"INV.LGL.HelpSeeking7\",\n",
    "    \"INV.LGL.HelpSeeking8\",\n",
    "    \"INV.LGL.HelpSeeking9\",\n",
    "    \"INV.LGL.HelpSeeking10\",\n",
    "    \"INV.LGL.HelpSeeking11\",\n",
    "    \"INV.LGL.HelpSeeking12\",\n",
    "    \"INV.LGL.HelpSeeking13\",\n",
    "    \"SBJ.FCT.Ethnicity\",\n",
    "    \"SBJ.FCT.GenderId\",\n",
    "    \"SBJ.FCT.Sex\",\n",
    "    \"SBJ.FCT.Sexuality\",\n",
    "    \"SBJ.LGL.Race.AmericanIndianAlaskaNative\",\n",
    "    \"SBJ.LGL.Race.Asian\",\n",
    "    \"SBJ.LGL.Race.HaitianBlackAfricanAmerican\",\n",
    "    \"SBJ.LGL.Race.HawaiianPacificIslander\",\n",
    "    \"SBJ.LGL.Race.MiddleEasternNorthAfrican\",\n",
    "    \"SBJ.LGL.Race.White\",\n",
    "    \"SBJ.LGL.Race.Multiple\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded23 = one_hot_encode(final23, get_yearly_columns(cat_cols, range(2020, 2024)))\n",
    "encoded24 = one_hot_encode(final24, get_yearly_columns(cat_cols, range(2020, 2024)))\n",
    "encoded25 = one_hot_encode(final25, get_yearly_columns(cat_cols, range(2020, 2024)))\n",
    "encoded26 = one_hot_encode(final26, get_yearly_columns(cat_cols, range(2020, 2024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standardizing the Columns in Each Year**\n",
    "In some of the years, there are no responses of a certain category for a \n",
    "question, so there are different sets of columns for each year. This function\n",
    "will create a new column of 0's for each category that is not recorded as a \n",
    "response for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_years(df, years):\n",
    "    for col in df.columns:\n",
    "        match = re.search(r\"(.+)(\\d{4})\", col)\n",
    "        if match:\n",
    "            var, year = match.groups()\n",
    "            for y in years:\n",
    "                if f\"{var}{y}\" not in df.columns:\n",
    "                    df[f\"{var}{y}\"] = 0\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded23 = standardize_years(encoded23, years)\n",
    "encoded24 = standardize_years(encoded24, years)\n",
    "encoded25 = standardize_years(encoded25, years)\n",
    "encoded26 = standardize_years(encoded26, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "output_dir = \"encoded\"\n",
    "encoded23.to_csv(os.path.join(output_dir, \"encoded23.csv\"), index=False)\n",
    "encoded24.to_csv(os.path.join(output_dir, \"encoded24.csv\"), index=False)\n",
    "encoded25.to_csv(os.path.join(output_dir, \"encoded25.csv\"), index=False)\n",
    "encoded26.to_csv(os.path.join(output_dir, \"encoded26.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper Function**\n",
    "\n",
    "To make it easier for us to grab all category columns for a categorical variable in our one-hot encoded dataframe, we create this helper function which uses RegEx to grab those for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_columns(df, variables):\n",
    "    cols = []\n",
    "    for var in variables:\n",
    "        cs = df.filter(regex=fr\"^{var}.+\").columns.tolist()\n",
    "        unique_cs = set()\n",
    "        for c in cs:\n",
    "            match = re.search(r\"(.+)(\\d{4})\", c)\n",
    "            if match:\n",
    "                c_name, _ = match.groups()\n",
    "                unique_cs.add(c_name)\n",
    "        cols += list(unique_cs)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of notebook :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #007BFF; height: 4px; width: 100%;\"></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs109a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
